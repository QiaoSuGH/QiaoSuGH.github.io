<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Matlab/Octave使用记</title>
    <link href="/2020/09/23/Matlab-Octave%E4%BD%BF%E7%94%A8%E8%AE%B0/"/>
    <url>/2020/09/23/Matlab-Octave%E4%BD%BF%E7%94%A8%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>Logistic Regression</title>
    <link href="/2020/09/15/Logistic%20Regression/"/>
    <url>/2020/09/15/Logistic%20Regression/</url>
    
    <content type="html"><![CDATA[<h5 id="如果使用Linear-Regression的方法去处理分类问题会怎样？"><a href="#如果使用Linear-Regression的方法去处理分类问题会怎样？" class="headerlink" title="如果使用Linear Regression的方法去处理分类问题会怎样？"></a>如果使用Linear Regression的方法去处理分类问题会怎样？</h5><p>考虑binary classification，那么我们获得拟合曲线之后，针对某个test data中的数据点计算y hat，那么结果如果大于0，则为class 1，否则为class 2。</p><p>注意我们这里的结果是获得了一条拟合曲线，因此其目标是尽可能的“接近”所有的数据点，但是显然这可能会是的拟合出来的曲线无法分开两个类。</p><img src="C:\Users\28425\AppData\Roaming\Typora\typora-user-images\image-20200915202002715.png" srcset="/img/loading.gif" alt="image-20200915202002715" style="zoom:50%;" /><img src="https://i.loli.net/2020/09/15/UGY23HfkJrwhB7O.png" srcset="/img/loading.gif" alt="image-20200915202655850" style="zoom:50%;" /><p>非常符合直觉：因为x要么属于C1，要么属于C2。因此我们首先获得从概率1：随便拿，拿到C1中的x的概率。之后我们需要计算总共两种可能得到x的概率：概率2。那么显然属于C1的概率是概率1除以概率2。</p><img src="https://i.loli.net/2020/09/15/EQ4Pqvs2LrDlSw5.png" srcset="/img/loading.gif" alt="image-20200915205752774" style="zoom:50%;" />]]></content>
    
    
    
    <tags>
      
      <tag>Machine Learning</tag>
      
      <tag>李宏毅机器学习笔记</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SDU2020图形学实验记录</title>
    <link href="/2020/09/15/SDU2020%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/09/15/SDU2020%E5%9B%BE%E5%BD%A2%E5%AD%A6%E5%AE%9E%E9%AA%8C%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<h3 id="Lab1"><a href="#Lab1" class="headerlink" title="Lab1"></a>Lab1</h3><blockquote><p>实验一：OpenGL基本使用</p><p>目标：自行配置OpenGL环境，熟悉使用OpenGL</p><p>要求：在屏幕上绘制出一个圆，然后绘制出圆的外接正方形，然后再绘制出正方形的外接圆，重复以上操作几次。</p></blockquote><p>迭代几次，每次更新圆的半径即可。</p><div class="hljs"><pre><code class="hljs c++"><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span><span class="hljs-meta-string">&lt;GL/glut.h&gt;</span></span><span class="hljs-meta">#<span class="hljs-meta-keyword">include</span> <span class="hljs-meta-string">&lt;math.h&gt;</span></span><span class="hljs-keyword">const</span> <span class="hljs-keyword">int</span> n = <span class="hljs-number">1000</span>;GLdouble R = <span class="hljs-number">0.05f</span>;<span class="hljs-keyword">const</span> GLdouble Pi = <span class="hljs-built_in">acos</span>(<span class="hljs-number">-1</span>);<span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">myDisplay</span><span class="hljs-params">(<span class="hljs-keyword">void</span>)</span></span><span class="hljs-function"></span>&#123;glClear(GL_COLOR_BUFFER_BIT);glBegin(GL_POINTS);GLdouble d = <span class="hljs-built_in">sqrt</span>(<span class="hljs-number">2</span>);<span class="hljs-keyword">int</span> num_iter = <span class="hljs-number">4</span>;<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>; i &lt; num_iter; ++i)&#123;<span class="hljs-keyword">for</span> (<span class="hljs-keyword">int</span> j = <span class="hljs-number">0</span>; j &lt; n; ++j)glVertex2f(R * <span class="hljs-built_in">cos</span>(<span class="hljs-number">2</span> * Pi / n * j), R * <span class="hljs-built_in">sin</span>(<span class="hljs-number">2</span> * Pi / n * j));GLdouble x1 = -R, y1 = R;<span class="hljs-keyword">while</span> (x1 &lt; R)&#123;glVertex2f(x1, R), glVertex2f(x1, -R);glVertex2f(-R, y1),glVertex2f(R, y1);x1 += <span class="hljs-number">0.001</span>;y1 -= <span class="hljs-number">0.001</span>;&#125;R *= d;&#125;glEnd();glFlush();&#125;<span class="hljs-function"><span class="hljs-keyword">int</span> <span class="hljs-title">main</span><span class="hljs-params">(<span class="hljs-keyword">int</span> argc, <span class="hljs-keyword">char</span>** argv)</span></span><span class="hljs-function"></span>&#123;glutInit(&amp;argc, argv);glutInitDisplayMode(GLUT_RGB | GLUT_SINGLE);glutInitWindowSize(<span class="hljs-number">1000</span>, <span class="hljs-number">1000</span>);glutInitWindowPosition(<span class="hljs-number">400</span>, <span class="hljs-number">100</span>);glutCreateWindow(<span class="hljs-string">"Lab01"</span>);glutDisplayFunc(&amp;myDisplay);glutMainLoop();<span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;&#125;</code></pre></div><h5 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h5><ul><li>一改动窗口就直接卡死</li></ul>]]></content>
    
    
    <categories>
      
      <category>Computer Graphics</category>
      
      <category>SDU2020图形学实验记录</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图形学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SDU2020ML Lab1 Regression</title>
    <link href="/2020/09/12/SDU2020ML_Lab1_Regression/"/>
    <url>/2020/09/12/SDU2020ML_Lab1_Regression/</url>
    
    <content type="html"><![CDATA[<blockquote><p>指导书以及数据集：<a href="https://funglee.github.io/ml/ml.html" target="_blank" rel="noopener">https://funglee.github.io/ml/ml.html</a></p></blockquote><h4 id="2D-Linear-Regression-and-Understanding-J-θ"><a href="#2D-Linear-Regression-and-Understanding-J-θ" class="headerlink" title="2D Linear Regression and Understanding J(θ)"></a>2D Linear Regression and Understanding J(θ)</h4><blockquote><p>要求：</p><ul><li>记录经过一次迭代之后theta的值</li><li>进行BGD，得到最终theta的值</li><li>根据上一步theta的值进行预测</li><li>作出J(θ)的图像</li></ul></blockquote><h5 id="代码"><a href="#代码" class="headerlink" title="代码"></a>代码</h5><div class="hljs"><pre><code class="hljs matlab"><span class="hljs-comment">%一元线性回归 使用BGD</span>x = load(<span class="hljs-string">'ex1_1x.dat'</span>);y = load(<span class="hljs-string">'ex1_1y.dat'</span>);<span class="hljs-built_in">figure</span>;<span class="hljs-built_in">plot</span>(x,y,<span class="hljs-string">'o'</span>);ylabel(<span class="hljs-string">'Height in meters'</span>);xlabel(<span class="hljs-string">'Age in years'</span>);m = <span class="hljs-built_in">length</span>(y);x = [<span class="hljs-built_in">ones</span>(m,<span class="hljs-number">1</span>),x];theta = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>);<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">theta</span> = <span class="hljs-title">bgd</span><span class="hljs-params">(x,y,num_iter,theta,alpha)</span></span>m = <span class="hljs-built_in">length</span>(y);n = <span class="hljs-built_in">length</span>(x(<span class="hljs-number">1</span>,:));  <span class="hljs-comment">%disp(n);</span>iter = <span class="hljs-number">0</span>;<span class="hljs-keyword">while</span>(<span class="hljs-built_in">true</span>)sum = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>);    H = x * theta;<span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:n<span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:m <span class="hljs-comment">%计算第i个偏导数--遍历样本点，求和</span>sum(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>) = sum(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>) + (H(<span class="hljs-built_in">j</span>)-y(<span class="hljs-built_in">j</span>))*x(<span class="hljs-built_in">j</span>,<span class="hljs-built_in">i</span>);<span class="hljs-keyword">end</span><span class="hljs-keyword">end</span>theta = theta - (alpha * sum) / m;iter = iter+<span class="hljs-number">1</span>;<span class="hljs-keyword">if</span> iter &gt; num_iter || <span class="hljs-built_in">abs</span>(theta)&lt;<span class="hljs-number">1e-4</span>      <span class="hljs-built_in">disp</span>(iter);<span class="hljs-keyword">break</span>;<span class="hljs-keyword">end</span><span class="hljs-keyword">end</span><span class="hljs-keyword">end</span>theta = bgd(x,y,<span class="hljs-number">1500</span>,theta,<span class="hljs-number">0.07</span>);<span class="hljs-built_in">hold</span> on; <span class="hljs-built_in">plot</span>(x(:,<span class="hljs-number">2</span>), x*theta, <span class="hljs-string">'-'</span>)<span class="hljs-built_in">legend</span>(<span class="hljs-string">'Training data'</span>, <span class="hljs-string">'Linear regression'</span>)boy1 = [<span class="hljs-number">1</span> , <span class="hljs-number">3.5</span>];boy2 = [<span class="hljs-number">1</span> , <span class="hljs-number">7</span>];<span class="hljs-built_in">plot</span>(boy1(:,<span class="hljs-number">2</span>),boy1 * theta, <span class="hljs-string">'sr'</span>);<span class="hljs-built_in">plot</span>(boy2(:,<span class="hljs-number">2</span>),boy2 * theta, <span class="hljs-string">'sr'</span>);<span class="hljs-comment">%作出J(theta)的图像</span><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">jij</span> = <span class="hljs-title">cal_j_vals</span><span class="hljs-params">(x,y,t)</span> </span>  m = <span class="hljs-built_in">length</span>(y);  jij = (x*t - y)' * (x*t - y) / (<span class="hljs-number">2</span> * m); <span class="hljs-keyword">end</span>;j_vals = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">100</span>,<span class="hljs-number">100</span>);theta0_vals = <span class="hljs-built_in">linspace</span>(<span class="hljs-number">-3</span>,<span class="hljs-number">3</span>,<span class="hljs-number">100</span>);theta1_vals = <span class="hljs-built_in">linspace</span>(<span class="hljs-number">-1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">100</span>);<span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span> = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(theta0_vals)  <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span> = <span class="hljs-number">1</span>:<span class="hljs-built_in">length</span>(theta1_vals)    t = [theta0_vals(<span class="hljs-built_in">i</span>); theta1_vals(<span class="hljs-built_in">j</span>)];    j_vals(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>) = cal_j_vals(x,y,t);  <span class="hljs-keyword">end</span>;<span class="hljs-keyword">end</span>;j_vals = j_vals';<span class="hljs-built_in">figure</span>;surf(theta0_vals, theta1_vals,j_vals);xlabel(<span class="hljs-string">'\theta_0'</span>); ylabel(<span class="hljs-string">'\theta_1'</span>);[X,Y] = <span class="hljs-built_in">meshgrid</span>(theta0_vals,theta1_vals);</code></pre></div><h5 id="问题："><a href="#问题：" class="headerlink" title="问题："></a>问题：</h5><ul><li>注意到我们在<code>theta = theta - (alpha * sum) / m</code>中除以了<code>m</code>，经过测试如果不除以<code>m</code>，那么结果的图像是没有线的。（？？？）但是这不是cost function的两种形式吗，为什么不除以<code>m</code>就不行？进一步延申：为什么代价函数的形式是这样的？（前面是否可以是任意实数–网上答案是“是”，如何证明？）</li></ul><h5 id="BGD算法实现"><a href="#BGD算法实现" class="headerlink" title="BGD算法实现"></a>BGD算法实现</h5><div class="hljs"><pre><code class="hljs matlab"><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">theta</span> = <span class="hljs-title">bgd</span><span class="hljs-params">(x,y,num_iter,theta,alpha)</span></span>m = <span class="hljs-built_in">length</span>(y);n = <span class="hljs-built_in">length</span>(x(<span class="hljs-number">1</span>,:));iter = <span class="hljs-number">0</span>;<span class="hljs-keyword">while</span>(<span class="hljs-built_in">true</span>)sum = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>);    H = x * theta;<span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:n<span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:m <span class="hljs-comment">%计算第i个偏导数--遍历样本点，求和</span>sum(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>) = sum(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>) + (H(<span class="hljs-built_in">j</span>)-y(<span class="hljs-built_in">j</span>))*x(<span class="hljs-built_in">j</span>,<span class="hljs-built_in">i</span>);<span class="hljs-keyword">end</span><span class="hljs-keyword">end</span>theta = theta - (alpha * sum) / m;iter = iter+<span class="hljs-number">1</span>;<span class="hljs-keyword">if</span> iter &gt; num_iter || <span class="hljs-built_in">abs</span>(theta)&lt;<span class="hljs-number">1e-4</span>      <span class="hljs-built_in">disp</span>(iter);<span class="hljs-keyword">break</span>;<span class="hljs-keyword">end</span><span class="hljs-keyword">end</span><span class="hljs-keyword">end</span><span class="hljs-comment">%计算J(θ):</span><span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">jij</span> = <span class="hljs-title">cal_j_vals</span><span class="hljs-params">(x,y,t)</span> </span>  m = <span class="hljs-built_in">length</span>(y);  jij = (x*t - y)' * (x*t - y) / (<span class="hljs-number">2</span> * m); <span class="hljs-keyword">end</span>;</code></pre></div><hr><h4 id="Multivariate-Linear-Regression"><a href="#Multivariate-Linear-Regression" class="headerlink" title="Multivariate Linear Regression"></a>Multivariate Linear Regression</h4><blockquote><p>要求：</p><ul><li>调整不同的学习率，使得损失函数的曲线形状接近于给出的曲线</li><li>比较不同的学习率得到的不同的损失函数曲线</li></ul></blockquote><h5 id="代码-1"><a href="#代码-1" class="headerlink" title="代码"></a>代码</h5><div class="hljs"><pre><code class="hljs matlab">x = load(<span class="hljs-string">'ex1_2x.dat'</span>);y = load(<span class="hljs-string">'ex1_2y.dat'</span>);<span class="hljs-comment">% x: living area and the number of bedrooms</span><span class="hljs-comment">% y: house price</span>m = <span class="hljs-built_in">length</span>(y);x = [<span class="hljs-built_in">ones</span>(m,<span class="hljs-number">1</span>),x];sigma = std(x);mu = <span class="hljs-built_in">mean</span>(x);<span class="hljs-comment">% preprocessing</span>x(:,<span class="hljs-number">2</span>) = (x(:,<span class="hljs-number">2</span>) - mu(<span class="hljs-number">2</span>)) ./ sigma(<span class="hljs-number">2</span>);x(:,<span class="hljs-number">3</span>) = (x(:,<span class="hljs-number">3</span>) - mu(<span class="hljs-number">3</span>)) ./ sigma(<span class="hljs-number">3</span>);n = <span class="hljs-number">3</span>;<span class="hljs-comment">%disp(n);</span>theta = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>)<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">theta</span> = <span class="hljs-title">bgd</span><span class="hljs-params">(x,y,alpha,iter,theta)</span></span>  <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:iter    m = <span class="hljs-built_in">length</span>(y);    n = <span class="hljs-number">3</span>;    sum = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>); <span class="hljs-comment">%记录偏导</span>    H = x * theta;<span class="hljs-comment">%变成一列</span>    <span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:n      <span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:m        sum(<span class="hljs-built_in">j</span>,<span class="hljs-number">1</span>) = sum(<span class="hljs-built_in">j</span>,<span class="hljs-number">1</span>) + (H(<span class="hljs-built_in">i</span>)-y(<span class="hljs-built_in">i</span>))*x(<span class="hljs-built_in">i</span>,<span class="hljs-built_in">j</span>);      <span class="hljs-keyword">end</span>    <span class="hljs-keyword">end</span>    theta = theta - (alpha*sum)/m;  <span class="hljs-keyword">end</span><span class="hljs-keyword">end</span>theta = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>);<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">val_of_j</span> = <span class="hljs-title">cal_j_vals</span><span class="hljs-params">(x,y,theta)</span> </span>  m = <span class="hljs-built_in">length</span>(y);  val_of_j = (x*theta - y)' * (x*theta - y) / (<span class="hljs-number">2</span> * m); <span class="hljs-keyword">end</span>;alpha = <span class="hljs-number">0.06</span>;J = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">50</span>,<span class="hljs-number">1</span>);<span class="hljs-keyword">for</span> num_iterations = <span class="hljs-number">1</span>:<span class="hljs-number">50</span>  J(num_iterations) = cal_j_vals(x,y,theta);  theta = bgd(x,y,alpha,num_iterations,theta);<span class="hljs-keyword">end</span>;<span class="hljs-built_in">figure</span>;p0 = <span class="hljs-built_in">plot</span>(<span class="hljs-number">0</span>:<span class="hljs-number">49</span>,J(<span class="hljs-number">1</span>:<span class="hljs-number">50</span>),<span class="hljs-string">'-'</span>);<span class="hljs-built_in">hold</span> on;xlabel(<span class="hljs-string">'Numbber of iterations'</span>)ylabel(<span class="hljs-string">'Cost J'</span>)<span class="hljs-comment">%批量改变alpha</span><span class="hljs-built_in">figure</span>;alpha = <span class="hljs-number">0.01</span>;<span class="hljs-keyword">while</span> alpha &lt; <span class="hljs-number">0.1</span>  J = <span class="hljs-built_in">zeros</span>(<span class="hljs-number">50</span>,<span class="hljs-number">1</span>);  theta = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>);  <span class="hljs-keyword">for</span> num_iterations = <span class="hljs-number">1</span>:<span class="hljs-number">50</span>  J(num_iterations) = cal_j_vals(x,y,theta);  theta = bgd(x,y,alpha,num_iterations,theta);  <span class="hljs-keyword">end</span>;  <span class="hljs-built_in">plot</span>(<span class="hljs-number">0</span>:<span class="hljs-number">49</span>,J(<span class="hljs-number">1</span>:<span class="hljs-number">50</span>),<span class="hljs-string">'-'</span>);  <span class="hljs-built_in">hold</span> on;  alpha = alpha * <span class="hljs-number">3</span>;<span class="hljs-keyword">end</span>;</code></pre></div><h5 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h5><h5 id="回答问题"><a href="#回答问题" class="headerlink" title="回答问题"></a>回答问题</h5><ul><li><p>如果学习率太小，例如0.001，那么损失函数下降得非常缓慢；</p><img src="https://i.loli.net/2020/09/20/ntKmgTByLr5b8WS.png" srcset="/img/loading.gif" alt="image-20200920212924281" style="zoom: 67%;" /><p>如果学习率太大，例如1，那么下降很快并且停止</p></li></ul><img src="https://i.loli.net/2020/09/20/EAt2OSreUXoIGkZ.png" srcset="/img/loading.gif" alt="image-20200920213034741" style="zoom:67%;" /><ul><li><p>进行预测</p><div class="hljs"><pre><code class="hljs matlab">x = load(<span class="hljs-string">'ex1_2x.dat'</span>);y = load(<span class="hljs-string">'ex1_2y.dat'</span>);<span class="hljs-comment">% x: living area and the number of bedrooms</span><span class="hljs-comment">% y: house price</span>m = <span class="hljs-built_in">length</span>(y);x = [<span class="hljs-built_in">ones</span>(m,<span class="hljs-number">1</span>),x];n = <span class="hljs-built_in">length</span>(x(<span class="hljs-number">1</span>,:));sigma = std(x);mu = <span class="hljs-built_in">mean</span>(x);x(:,<span class="hljs-number">2</span>) = (x(:,<span class="hljs-number">2</span>) - mu(<span class="hljs-number">2</span>)) ./ sigma(<span class="hljs-number">2</span>);x(:,<span class="hljs-number">3</span>) = (x(:,<span class="hljs-number">3</span>) - mu(<span class="hljs-number">3</span>)) ./ sigma(<span class="hljs-number">3</span>);theta = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>);<span class="hljs-function"><span class="hljs-keyword">function</span> <span class="hljs-title">theta</span> = <span class="hljs-title">bgd</span><span class="hljs-params">(x,y,num_iter,theta,alpha)</span></span>m = <span class="hljs-built_in">length</span>(y);n = <span class="hljs-built_in">length</span>(x(<span class="hljs-number">1</span>,:));iter = <span class="hljs-number">0</span>;<span class="hljs-keyword">while</span>(<span class="hljs-built_in">true</span>)sum = <span class="hljs-built_in">zeros</span>(n,<span class="hljs-number">1</span>);    H = x * theta;<span class="hljs-keyword">for</span> <span class="hljs-built_in">i</span>=<span class="hljs-number">1</span>:n<span class="hljs-keyword">for</span> <span class="hljs-built_in">j</span>=<span class="hljs-number">1</span>:m <span class="hljs-comment">%计算第i个偏导数--遍历样本点，求和</span>sum(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>) = sum(<span class="hljs-built_in">i</span>,<span class="hljs-number">1</span>) + (H(<span class="hljs-built_in">j</span>)-y(<span class="hljs-built_in">j</span>))*x(<span class="hljs-built_in">j</span>,<span class="hljs-built_in">i</span>);<span class="hljs-keyword">end</span><span class="hljs-keyword">end</span>theta = theta - (alpha * sum) / m;iter = iter+<span class="hljs-number">1</span>;<span class="hljs-keyword">if</span> iter &gt; num_iter || <span class="hljs-built_in">abs</span>(theta)&lt;<span class="hljs-number">1e-4</span>      <span class="hljs-built_in">disp</span>(iter);<span class="hljs-keyword">break</span>;<span class="hljs-keyword">end</span><span class="hljs-keyword">end</span><span class="hljs-keyword">end</span>theta = bgd(x,y,<span class="hljs-number">1500</span>,theta,<span class="hljs-number">0.07</span>);<span class="hljs-built_in">disp</span>(theta);pre_x = [<span class="hljs-number">1</span>,<span class="hljs-number">1650</span>,<span class="hljs-number">3</span>];pre_x(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>) = (pre_x(<span class="hljs-number">1</span>,<span class="hljs-number">2</span>) - mu(<span class="hljs-number">2</span>)) / sigma(<span class="hljs-number">2</span>);pre_x(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>) = (pre_x(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>) - mu(<span class="hljs-number">3</span>)) / sigma(<span class="hljs-number">3</span>);<span class="hljs-built_in">disp</span>(pre_x * theta);</code></pre></div><p><img src="https://i.loli.net/2020/09/20/74zCd832WrA1etQ.png" srcset="/img/loading.gif" alt="image-20200920215250588"></p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>SDU2020 ML记录</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Regression</title>
    <link href="/2020/09/07/Linear%20Regression/"/>
    <url>/2020/09/07/Linear%20Regression/</url>
    
    <content type="html"><![CDATA[<h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><h4 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h4><p>预测宝可梦的CP值是一个典型的回归问题。考虑三个基本步骤：选定model；定义loss function；training data：根据loss function/找到一个最好的model。</p><blockquote><p>我们在选定model时会定义各个参数，而loss function就是这些参数的函数–用以评估这些参数的好坏</p></blockquote><p>在这个例子中我们使用<strong>？？？Model</strong>，接着我们得到了loss function。那么如何求解loss function的最小值从而得到最好的model？–<strong>梯度下降法 Gradient Descent</strong></p><h4 id="Gradient-Descent"><a href="#Gradient-Descent" class="headerlink" title="Gradient Descent"></a>Gradient Descent</h4><h5 id="基本操作步骤："><a href="#基本操作步骤：" class="headerlink" title="基本操作步骤："></a>基本操作步骤：</h5><p>这节课里只是简单地介绍了一下Gradient Descent是如何操作的：首先从一元函数求极值开始，我们从某点<code>W0</code>开始，根据导数（这里注意使用梯度下降的前提是loss function是可微的）判断<code>W0</code>应该增大或者减小，然后循环进行这样的变化，直到导数为0。这里便有了<strong>learning rate</strong>这个参数–<code>W0</code>的变化每次都是增加或者减少<code>learning rate * 导数值</code>。推广到二元函数的情形也是一致的：分别求两个变量的偏导数。</p><h5 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h5><p>但是以上只是简单的操作/演示Gradient Descent如何进行，还有一些问题：</p><ul><li>显然对于任意一个二元函数来说，可能local optimal 并非global optimal–由于是从某<code>W0</code>点开始的，因此可能在此附近陷入local minima，而得到不全局的minima。为了让Gradient Descent有效我们必须保证loss function没有局部最优解。</li><li>这里延申出一个问题：我们上面定义的loss function是<strong>凸函数</strong>，只有global optimal。所以：<strong>凸函数的性质？</strong></li></ul><h4 id="对于结果的该进"><a href="#对于结果的该进" class="headerlink" title="对于结果的该进"></a>对于结果的该进</h4><h5 id="其他model"><a href="#其他model" class="headerlink" title="其他model"></a>其他model</h5><p>事实上我们可以尝试增加<code>Xi</code>的次数–使用更高阶数去进行拟合。这样结果就是在训练集上我们的error越来越小，（低次的式子是高次的式子的特殊情况。<strong>考虑可视化的表现：使用更高次数的式子去拟合，其对应的function set包含了低次式对应的function set，所以training data上表现更好是自然的</strong>），但是在testing data上的表现却未必。</p><h5 id="overfitting-过拟合-以及-regularization-正则化"><a href="#overfitting-过拟合-以及-regularization-正则化" class="headerlink" title="overfitting 过拟合 以及 regularization 正则化"></a>overfitting 过拟合 以及 regularization 正则化</h5><p>上面的现象便是过拟合。</p><p>我们可以通过regularization来解决这个问题：在原本loss function的基础上增加一项。<strong>这样的结果是函数变得更加平滑，从而结果更好（平滑意味着输出对输入敏感性降低，从而输入的一些noise对于结果的影响更小）</strong></p><img src="https://gitee.com/Sakura-gh/ML-notes/raw/master/img/regularization.png" srcset="/img/loading.gif" alt="regularization" style="zoom: 33%;" /><p><strong>（这里的参数需要手动调整，从而使其在平滑与不平滑之间达到一个较好的状态）</strong></p><h4 id="问题-1"><a href="#问题-1" class="headerlink" title="问题"></a>问题</h4><ul><li>凸函数 可微 偏导数</li><li>正则化处理过程中增加一项的数学上的理解</li><li>model有哪些？</li></ul><hr><h3 id="对于Gradient-Descent的理解"><a href="#对于Gradient-Descent的理解" class="headerlink" title="对于Gradient Descent的理解"></a>对于Gradient Descent的理解</h3><h4 id="方向导数"><a href="#方向导数" class="headerlink" title="方向导数"></a>方向导数</h4><hr>]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>李宏毅机器学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>李宏毅2020机器学习课程记录</title>
    <link href="/2020/09/07/%E6%9D%8E%E5%AE%8F%E6%AF%852020%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/09/07/%E6%9D%8E%E5%AE%8F%E6%AF%852020%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Machine Learning</category>
      
      <category>李宏毅机器学习笔记</category>
      
    </categories>
    
    
    <tags>
      
      <tag>机器学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GAMES101记录</title>
    <link href="/2020/07/17/GAMES101%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/07/17/GAMES101%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>Computer Graphics</category>
      
      <category>GAMES101</category>
      
    </categories>
    
    
    <tags>
      
      <tag>图形学</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客搭建过程记录</title>
    <link href="/2020/04/24/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/"/>
    <url>/2020/04/24/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%E8%AE%B0%E5%BD%95/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>程序设计思维与实践</category>
      
      <category>代码模板</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
